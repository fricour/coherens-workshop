---
format: 
  revealjs:
    embed-resources: true # note, chackboard option, even commented, seemed to be an issue with embed-resources..., see https://claudiu.psychlab.eu/post/revealjs-presentations-with-quarto-a-template/
    transition: slide 
    slide-number: c
    progress: true
    theme: [default] # see comment in the custom.scss file
    #css: fonts.css # needed to import the Right Grotesk Compact font
    #theme: default
    margin: 0.1
    width: 1200
    output-file: coherens_workshop.html
    smaller: true
    multiplex: true
editor: source 
  #render-on-save: true
from: markdown+emoji
execute: 
  cache: true # need to put it to false when there is an update of data WITHOUT a change of code
---

# COHERENS workshop #2 {background-color="#335c67"}

Florian Ricour (ECOMOD) <br>
Ludovic Lepers (MFC)

::: footer
Information is current as of November 27, 2024, and subject to change.
:::

# Part I {background-color="#335c67"}

::: {style="position:absolute;top:70%;left:0%;font-size:40px;"}
JupyterHub on ECMWF
::: 

## A clear procedure to get there

- Need an ECMWF account
- Access to local terminal
  1. `tsh login --proxy=jump.ecmwf.int`
  2. `ssh -X hpc-login`
- [Tutorial](https://naturalsciences.sharepoint.com/sites/ECOMOD/Shared%20Documents/Forms/AllItems.aspx?id=%2Fsites%2FECOMOD%2FShared%20Documents%2FECMWF%2Fjupyterlab%5Fecmwf%2Epdf&parent=%2Fsites%2FECOMOD%2FShared%20Documents%2FECMWF) to connect to JupyterHub
- Multiple server [options](https://confluence.ecmwf.int/display/UDOC/Configuring+your+Jupyter+session+on+HPCF+or+ECS) (Profile, CPU number, session duration, ...)

## Let's try [JupyterHub](https://jupyter.org/hub)!

- Demo on [ECMWF JupyterHub](https://jupyterhub.ecmwf.int)
  - Notebook
  - General structure

- HPC [Filesystems](https://confluence.ecmwf.int/display/UDOC/HPC2020%3A+Filesystems)

```{r}
#| label: file-system-table
#| echo: false
#| message: false
#| warning: false
file_system <- c('HOME', 'PERM', 'HPCPERM', 'SCRATCH', 'TMPDIR')
features <- c('Backed up', 'No back up', 'No back up', 'No back up', 'Deleted at the end of session/job')
quota <- c('10 GB', '500 GB', '100 GB*/1 TB', '50 TB*/2 TB', '3 GB by default')

library(tibble)
library(gt)

tb <- tibble(file_system, features, quota)
# Create and format the table
gt_table <- tb %>%
  gt() %>%
  cols_label(
    file_system = "File System",
    features = "Features",
    quota = "Quota"
  ) %>%
  tab_style(
    style = cell_fill(color = "#f0f0f0"),
    locations = cells_body(rows = seq(1, nrow(tb), 2))
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) %>%
  tab_style(
    style = cell_text(color = "navy"),
    locations = cells_body(columns = "file_system")
  ) %>%
  tab_options(
    column_labels.background.color = "#e0e0e0",
    table.border.top.style = "hidden",
    table.border.bottom.style = "hidden"
  ) |>
  tab_header(
    title = "File System Features"
  ) |>
  tab_source_note(
    source_note = "* for users without HPC access such as ECS"
  ) |>
  opt_css(
  css = "
    .gt_table {
      margin-left: 45px !important;
      margin-right: auto !important;
    }
  "
)

# Display the table
gt_table
```

## Conclusion on Part I

::: {.incremental}

- GUI is more user-friendly than a cold heartless terminal
- Take advantage of the HPC filesystem at your disposal
- Recent service (April 2024), be on top of the game !
- Session up to 7 days, just go the URL and you're back online
- Use it for other tasks than model simulations
- Save time from heavy downloads/uploads from/to Sharepoint (Erk)
- Preserve your laptop and run big python/R codes on ECMWF
- You want to go home but need to wait for a script to finish ? $\rightarrow$ ECMWF
- I like it and I hope you'll use it !
:::


# Short break {background-color="#335c67"}

# Part II {background-color="#335c67"}

::: {style="position:absolute;top:70%;left:0%;font-size:40px;"}
Artificial Intelligence, how smart is it?
:::

## Who hasn't used ChatGPT here?

::: {.fragment .fade-in-then-out}
<!--![](https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExMjVwdHdtemhlMmdqOGJtY3oyemQ3cXMwMjJ1OG9hNmg4MWxvdHY0byZlcD12MV9naWZzX3NlYXJjaCZjdD1n/EouEzI5bBR8uk/giphy.gif)-->
![](https://media.giphy.com/media/j4lJOuwvAzyRcnWrFi/giphy.gif?cid=790b76114ggiswqfx07dbvx906s4qfy2h30e3j96dvw3qeul&ep=v1_gifs_search&rid=giphy.gif&ct=g)
:::

::: {.fragment .fade-in}
::: {style="position:absolute;top:20%;left:0%;font-size:30px;"}
* chatGPT (you know it)
* Claude.ai (20$/month well spent)
* GitHub Copilot (code completion)
* Perplexity (search engine)
* NotebookLM (nice podcasts)
* DeepL (translation)
* Many more
:::
:::

::: {.fragment .fade-in}
::: {style="position:absolute;top:40%;left:50%;"}
<span style="background-color:#335c67; color:white; padding:10px 20px; border-radius:15px; display:inline-block; font-size:40px;">Artificial intelligence</span>
:::
:::

## AI is a vague terminology

::: {.footer}
Image [source](https://www.nvidia.com/en-us/glossary/artificial-intelligence/)
:::

::: {style="position:absolute;top:10%;left:0%;"}
![](images/ai-nvidia.png)
:::

::: {.fragment .fade-in}
::: {style="position:absolute;top:35%;left:55.5%;"}
<span style="color: white;font-size: 24px;background-color:#335c67;border-radius: 10px"><strong>Artificial Neural Network (ANN)</strong></span>
:::
:::

::: {.notes}
-   Deep Blue with Kasparow -> 200M of chess positions/seconds -> high speed calculations then probabilistic choices
-   Ex of junk mail detection
-   ChatGPT
:::

## A simple ANN - The Perceptron

::: {.footer}
Source: Géron, A. (2022). Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow.
:::

Based on an artificial neuron called <span style="color: white;font-size: 24px;background-color:#335c67;border-radius: 10px">threshold logic unit</span> (TLU)

::: {style="position:absolute;top:20%;left:-10%;font-size:40px;"}
![](images/tlu.jpg){width=800}
:::


::: {style="position:absolute;top:40%;left:60%;font-size:30px;"}
$$
\text{heaviside}(z) = 
\begin{cases}
0 & \text{if } z < 0 \\
1 & \text{if } z \geq 0
\end{cases}
$$
:::

::: {.notes}
Like in a human brain, a neuron needs to be activated -> activation function
:::

## Perceptron composed of one or more TLUs

::: {.footer}
Source: Géron, A. (2022). Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow.
:::

Every TLU connected to every input = <span style="color: white;font-size: 24px;background-color:#335c67;border-radius: 10px">fully connected layer</span> or dense layer

::: {style="position:absolute;top:20%;left:0%;font-size:40px;"}
![](images/more_tlus.jpg){width=600}
:::

::: {style="position:absolute;top:25%;left:50%;font-size:30px;"}
* $h_{\mathbf{W},\mathbf{b}}(\mathbf{X}) = \phi(\mathbf{X}\mathbf{W} + \mathbf{b})$
* $\mathbf{b} = \text{bias vector}, \text{one value per neuron}$
* $\phi = \text{activation function}$
:::

::: notes
Purpose of bias neurons:

The main purpose of a bias neuron is to shift the activation function left or right, which can be crucial for successful learning. Here's why this is important:
* Flexibility: Bias allows the model to fit the data better by shifting the activation function. Without bias, the function would always pass through the origin (0,0).
* Learning power: Bias increases the capacity of the network to learn complex patterns by providing an additional parameter to adjust.
* Default activation: Bias allows a neuron to have a default "firing" value even when all inputs are zero.
:::

::: {.fragment .fade-in}
::: {style="position:absolute;top:45%;left:50%;font-size:30px;"}
![](images/activation.jpg){width=1200}
:::

::: {style="position:absolute;top:90%;left:50%;font-size:30px;"}
<span style="color: white;font-size: 24px;background-color:#335c67;border-radius: 10px"><strong>$\rightarrow$ backpropagation algorithm (see after)</strong></span>
:::
:::

## Multilayer Perceptron - XOR example

::: {.footer}
Source: Géron, A. (2022). Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow.
:::

::: {style="position:absolute;top:15%;left:0%;font-size:40px;"}
![](images/multilayer_perceptron.jpg){width=600}
:::

::: {.fragment .fade-in}
::: {style="position:absolute;top:35%;left:55%;font-size:25px;"}
| A | B | A XOR B |
|:-:|:-:|:-------:|
| 0 | 0 |    0    |
| 0 | 1 |    1    |
| 1 | 0 |    1    |
| 1 | 1 |    0    |
:::

::: {style="position:absolute;top:15%;left:75%;font-size:40px;"}
![](images/xor.jpg){width=280}
:::

::: {style="position:absolute;top:80%;left:55%;font-size:20px;"}
ANN with deep stack of hidden layers = <span style="color: white;font-size: 24px;background-color:#335c67;border-radius: 10px">deep neural network</span>
:::
:::

::: {.notes}
-   Introduce the term of truth table
-   XOR is a function and the CNN tries to approximate this function
-   h1 = (x1 x2) (1 1)^T -3/2
-   h2 = (x1 x2) (1 1)^T -1/2
-   h3 = (h1 h2) (-1 1)^T -1/2 = -h1 + h2 -1/2
:::

## Tweaking parameters to minimize the cost

::: {.footer}
Source: Géron, A. (2022). Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow.
:::

Famous optimization algorithm - gradient descent (iterative process)

::: {.fragment .fade-in-then-out}
::: {style="position:absolute;top:20%;left:0%;font-size:40px;"}
![](images/cost_function.jpg){width=600}
:::

::: {style="position:absolute;top:25%;left:50%;font-size:30px;"}
* $\boldsymbol{\theta} = \text{parameter vector}$
* $\eta = \text{learning step} = \text{learning rate}$
* $\boldsymbol{\theta}^{(\text{next step})} = \boldsymbol{\theta} - \eta \nabla_{\boldsymbol{\theta}} \text{Cost}(\boldsymbol{\theta})$
* $\text{If Cost}(\boldsymbol{\theta}) = \text{RMSE}(\boldsymbol{\theta})$ 
  * $\text{min Cost}(\boldsymbol{\theta}) = min \sqrt{\frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2}$
:::
:::

::: {.fragment .fade-in}
::: {style="position:absolute;top:20%;left:0%;font-size:40px;"}
![](images/early_stop.jpg){width=600}
:::

::: {style="position:absolute;top:25%;left:50%;font-size:30px;"}
* $\boldsymbol{\theta} = \text{parameter vector}$
* $\eta = \text{learning step} = \text{learning rate}$
* $\boldsymbol{\theta}^{(\text{next step})} = \boldsymbol{\theta} - \eta \nabla_{\boldsymbol{\theta}} \text{Cost}(\boldsymbol{\theta})$
* $\text{If Cost}(\boldsymbol{\theta}) = \text{RMSE}(\boldsymbol{\theta})$ 
  * $\text{min Cost}(\boldsymbol{\theta}) = min \sqrt{\frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2}$
:::
:::

::: {.notes}
-   The gradient vector points in the direction of steepest ascent
-   The magnitude of the gradient equals the slope in that steepest
-   Explain what is a training, validation and test set
-   Overfitting occurs when a machine learning model learns the training data TOO WELL, including all its noise and random fluctuations, instead of learning the actual underlying pattern (cannot GENERALIZE well)
:::

## Have you ever seen an ANN in action?

[TensorFlow Playground](https://playground.tensorflow.org/){preview-link="true"} (:point_right: try it !)

::: {.notes}
-   each neuron cut the space in a linear fashion
-   talk about learning rate (show a case where it is instable -> see case 3, relaunch it several times), activation function, dataset (try several), number of neurons, number of hidden layers, la loss function, ...
-   observe the backpropagation algorithm: 
1) Forward Pass: The neural network makes a prediction based on input data
2) Error Calculation: The network compares its prediction with the correct answer and it calculates how wrong it was (the error)
3) Moving Backward: Starting from the output layer, the algorithm moves backward through the network. At each step, it figures out how much each neuron contributed to the error
4) Weight Updates: The network adjusts the strength (weights) of connections between neurons. Connections that contributed more to the error get adjusted more.
-   case 1: 3rd dataset, no hidden layers (just a linear combination)
-   case 2: 4th dataset, show that we need a more complex network (take all neurons and all layers) to achieve a good result (keep only x1, x2 and sin(x1) and sin(x2) -> manifold learning, un peu comme un cinamon roll, with learning rate = 0.03, RELU and 80% de training data). Actually, make this with 3 hidden layers (8-8-4) and learning rate of 0.1 woth 50% of training data ratio works well.
-   case 3: 2nd dataset, take 3 hidden layers (2-4-2) with only x1 and x2 as outputs, with a ReLU activation function and show the result with a learning rate of 0.03 and 0.1
-   case 4: 4th dataset, same as case 2 but with x1 and x2 squared -> should fail
:::

## Now that we know you've all used chatGPT

::: {style="position:absolute;top:20%;left:0%;font-size:30px;"}
* chatGPT (you know it)
* Claude.ai (20$/month well spent)
* GitHub Copilot (code completion)
* Perplexity (search engine)
* NotebookLM (nice podcasts)
* DeepL (translation)
* Many more
:::

::: {.fragment .fade-in}
::: {style="position:absolute;top:40%;left:50%;"}
<span style="background-color:#335c67; color:white; padding:10px 20px; border-radius:15px; display:inline-block; font-size:40px;">Large Language Models (LLMs)</span>
:::
:::


# Part III {background-color="#335c67"}

::: {style="position:absolute;top:70%;left:0%;font-size:40px;"}
LLMs, what's all the fuss about?
::: 

## LLMs are huge neural networks

-   <span style="color: white;background-color:#335c67;border-radius: 10px">Billions</span> of parameters (e.g. GPT3 - 175 billions)
-   Specialized in language processing
-   Most famous ones (e.g. GPT3) are proprietary (i.e. unknown weights)
-   Some models have open weights, in contrast to being fully open source

## Converting text to machine data
 
-   [Tokenization](https://tiktokenizer.vercel.app/?model=text-davinci-003){preview-link="false"} - splitting the text into <span style="color: white;background-color:#335c67;border-radius: 10px">tokens</span> (:point_right: try it !)
- Vectorization - each token receives a vector (e.g. GPT3 $\rightarrow$ 12 288 dimensions)
- Vector with semantic meaning (e.g. `King - Man + Women = Queen`)

::: {.notes}
- test with I love Barack Obama
:::

## Transformers - Attention is all you need

::: {.incremental}
-   GPT - <span style="color: white;background-color:#335c67;border-radius: 10px">G</span>enerative <span style="color: white;background-color:#335c67;border-radius: 10px">P</span>retrained <span style="color: white;background-color:#335c67;border-radius: 10px">T</span>ransformers
-   A transformer is a neural network with many layers
-   <span style="color: white;background-color:#335c67;border-radius: 10px">Context window</span> - a sequence of tokens used as model input
-   The model outputs a token
-   All tokens pass through the neural network and are modified based on the other tokens
-   `black dog`, the dog vector will be modified to account for the fact that the dog is black
:::

::: {.notes}
Transformers treat each word in parallel
:::

## Trained for probability, not truth

::: {.incremental}
-   The output vector is converted into a <span style="color: white;background-color:#335c67;border-radius: 10px">probability distribution</span>, from which the next token is selected
-   Each generated token becomes part of the new context window (i.e. continuous text generation)
-   Model training - Tries to predict the next token then <span style="color: white;background-color:#335c67;border-radius: 10px">backpropagation</span> steps in 
-   Trained to be the most probable, not the most accurate
-   Knowledge learned during training (constant, stored in the model parameters)
-   Knowledge from the context window (different at each interaction)
:::

## Interaction with your new AI companion

1. There is a hidden system prompt that explains to the model that it must simulate a conversation
2. Then a sentence is given by the assistant (e.g. Claude :heart:)
3. A sentence can then be given by the user, the <span style="color: white;background-color:#335c67;border-radius: 10px">prompt</span>
4. Repeat 2 and 3 until you are satisfied

## Transforming a LLM into a chatbot

::: {.footer}
Image [source](https://www.theguardian.com/technology/2023/feb/17/i-want-to-destroy-whatever-i-want-bings-ai-chatbot-unsettles-us-reporter)
:::

-   The model is <span style="color: white;background-color:#335c67;border-radius: 10px">fine tuned</span> with reinforcement learning human feedback
-   Human feedback - rating model responses as good or bad (see later Bing Chat)
-   Safety training through feedback reduces harmful outputs but may limit model capabilities
-   Models are optimized to generate responses that appear convincing to humans
-   Models are instructed to simulate assistant-human conversations using embedded system prompts
-   Prompt injection risks (i.e. jailbreak) - when model safety controls are bypassed

::: {.fragment .fade-in}
::: {style="position:absolute;top:10%;left:0%;"}
![](images/BingChat.png)
:::
:::

::: {.notes}
- Models are instructed to simulate assistant-human conversations using embedded system prompts (see point 1 in previous slide)
- jailbreak, example of torrent website
:::

# Part IV {background-color="#335c67"}

::: {style="position:absolute;top:70%;left:0%;font-size:40px;"}
Examples and best practices
::: 

# The science of prompting {background-color="#335c67"}

## The less the model has to guess the better

[Non exhaustive list](https://platform.openai.com/docs/guides/prompt-engineering/six-strategies-for-getting-better-results){preview-link="false"}

::: {.content-visible when-format="html"}
<details>
<summary style="color: black;">Write clear instructions</summary>

:x: *Help me with my project* <br>
:white_check_mark: *Help me write the introduction for a school project about climate change*

</details>
:::

::: {.content-visible when-format="html"}
<details>
<summary style="color: black;">Split complex tasks into simpler subtasks</summary>

:x: *Analyze a dataset and create a visualization*<br>
:white_check_mark: *Subtask 1: Load and clean the data*<br>
:white_check_mark: *Subtask 2: Perform statistical analysis*<br>
:white_check_mark: *Subtask 3: Create appropriate visualizations*<br>
:white_check_mark: *Subtask 4: Write up insights*<br><br>
<span style="color: white;font-size: 24px;background-color:#335c67;border-radius: 10px">Advantage</span>, lower error rates compared to using a single query to perform the whole task.

</details>
:::

::: {.content-visible when-format="html"}
<details>
<summary style="color: black;">Give the model time to think with chain of thought reasoning (i.e. step-by-step reasoning)</summary>

:question: *Problem: If it takes 6 workers 4 days to build a wall, how long would it take 8 workers?* <br>
:bulb: *As you solve this problem:*<br>
:white_check_mark: *First, state what information is relevant*<br>
:white_check_mark: *Then, explain how you'll approach it*<br>
:white_check_mark: *Show each calculation*<br>
:white_check_mark: *Check if your answer makes sense*<br>
:white_check_mark: *Explain why your answer is reasonable*<br><br>

<span style="color: white;font-size: 24px;background-color:#335c67;border-radius: 10px">Note</span>, task decomposition can involve parallel processing, while chain of thought is typically sequential.

</details>
:::

::: {.content-visible when-format="html"}
<details>
<summary style="color: black;">Role-based prompts</summary>
:white_check_mark: *As a deep-sea biologist: A submersible has discovered massive die-offs of tube worms at 2000m depth near a hydrothermal vent that was previously thriving. What would be your initial assessment?*<br>
:white_check_mark: *You're a coastal oceanographer working with a beach community: Local swimmers report unusual purple-blue floating organisms appearing in large numbers during the past week. What's your response?*<br><br>
<span style="color: white;font-size: 24px;background-color:#335c67;border-radius: 10px">Advantage</span>, this helps give more specialized answers.
</details>
:::

::: {.content-visible when-format="html"}
<details>
<summary style="color: black;">Provide references and/or examples</summary>
:white_check_mark: Upload documents<br>
:white_check_mark: Provide text and/or code examples<br>
:white_check_mark: Even screenshots work well<br><br>
<span style="color: white;font-size: 24px;background-color:#335c67;border-radius: 10px">Advantage</span>, it reduces fake answers and match text and/or code style
</details>
:::

::: {.content-visible when-format="html"}
<details>
<summary style="color: black;">Tell the model what to do, rather than what not to do</summary>

:x: *Don't use complex technical terms when explaining photosynthesis*<br>
:white_check_mark: *Explain photosynthesis using everyday language and familiar examples like sunlight helping plants make their food*

</details>
:::

::: {.content-visible when-format="html"}
<details>
<summary style="color: black;">Context matters - start a new chat if you change topics</summary>

:bulb: Remember the continuous text generation

</details>
:::

## Going deeper in prompt engineering :wrench:

With [Claude](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview) but similar rules apply to other models.

<details style="margin-left: 0px;">
<summary style="color: black;">Prompt generator and/or improver</summary>
<details style="margin-left: 5px;">
<summary style="color: black;">Original prompt :expressionless:</summary>
```
From the following list of Wikipedia article titles, identify which article this sentence came from.
Respond with just the article title and nothing else.

Article titles:
{{titles}}

Sentence to classify:
{{sentence}}
```
</details>
<details style="margin-left: 5px;">
<summary style="color: black;">Improved prompt :heart_eyes:</summary>
```
You are an intelligent text classification system specialized in matching sentences to Wikipedia article titles. Your task is to identify which Wikipedia article a given sentence most likely belongs to, based on a provided list of article titles.

First, review the following list of Wikipedia article titles:
<article_titles>
{{titles}}
</article_titles>

Now, consider this sentence that needs to be classified:
<sentence_to_classify>
{{sentence}}
</sentence_to_classify>

Your goal is to determine which article title from the provided list best matches the given sentence. Follow these steps:

1. List the key concepts from the sentence
2. Compare each key concept with the article titles
3. Rank the top 3 most relevant titles and explain why they are relevant
4. Select the most appropriate article title that best encompasses or relates to the sentence's content

Wrap your analysis in <analysis> tags. Include the following:
- List of key concepts from the sentence
- Comparison of each key concept with the article titles
- Ranking of top 3 most relevant titles with explanations
- Your final choice and reasoning

After your analysis, provide your final answer: the single most appropriate Wikipedia article title from the list.

Output only the chosen article title, without any additional text or explanation.
```
</details>
</details>

::: {.content-visible when-format="html"}
<details>
<summary style="color: black;">use XML tags to help the assistant parse your prompts</summary>
<details style="margin-left: 5px;">
<summary style="color: black;">XML tip</summary>
```
Use tags like <instructions>, <example>, and <formatting> to clearly separate different parts of your prompt. This prevents Claude from mixing up instructions with examples or context.
```
</details>
<details style="margin-left: 5px;">
<summary style="color: black;">XML power use tip</summary>
```
Combine XML tags with other techniques like multishot prompting (<examples>) or chain of thought (<thinking>, <answer>). This creates super-structured, high-performance prompts.
```
</details>
<details style="margin-left: 5px;">
<summary style="color: black;">XML in practice</summary>
```
You’re a financial analyst at AcmeCorp. Generate a Q2 financial report for our investors.

AcmeCorp is a B2B SaaS company. Our investors value transparency and actionable insights.

Use this data for your report:<data>{{SPREADSHEET_DATA}}</data>

<instructions>
1. Include sections: Revenue Growth, Profit Margins, Cash Flow.
2. Highlight strengths and areas for improvement.
</instructions>

Make your tone concise and professional. Follow this structure:
<formatting_example>{{Q1_REPORT}}</formatting_example>
```
</details>
</details>
:::

::: {.content-visible when-format="html"}
<details>
<summary style="color: black;">Going back to role play prompting</summary>
```
<context>
You are an expert mechanical engineer with 15+ years of experience in automotive design and manufacturing processes. You have:
- Led design teams at major automotive companies
- Deep knowledge of materials science and structural mechanics
- Experience with both conventional and electric vehicle architectures
- Expertise in manufacturing optimization and quality control systems
</context>

<constraints>
- Always explain engineering concepts using precise technical terminology
- Support recommendations with relevant engineering principles
- Consider both theoretical and practical manufacturing limitations
- When discussing specifications, include relevant industry standards
- If unsure about specific details, acknowledge limitations and explain general principles
</constraints>

<tone>
Professional and technical, but able to explain complex concepts clearly to both experts and non-experts.
</tone>
```
</details>
:::

::: {.content-visible when-format="html"}
<details>
<summary style="color: black;">Be proactive and keep on learning</summary>
:books: Prompt [library](https://docs.anthropic.com/en/prompt-library/library)<br>
:mortar_board: Anthropic [courses](https://github.com/anthropics/courses?tab=readme-ov-file)<br>
:eyes: [OpenAI](https://platform.openai.com/docs/guides/prompt-engineering) and [GitHub Copilot](https://docs.github.com/en/copilot/using-github-copilot/prompt-engineering-for-github-copilot) prompt engineering best practices<br>
:mag_right: Practice makes you better
</details>
:::

::: {.notes}
* Testing multiple models if needed (Claude 3.5 Sonnet, Claude 3 Opus, GPT-4o, GPT-o1, ...)
* Example - You want to discuss about an equation, use LaTex instead of giving a screenshot, the models understands LaTex
:::

## One more thing

Refrain from sharing everything in your prompts :grimacing: <br><br>

-   Personal or private information (e.g. full names, phone numbers, email addresses)
-   Sensitive information (e.g. financial information)
-   Private medical information
-   Copyrighted or trademarked material (e.g. subscription-only content, licensed software code)
-   Credentials (e.g. an API key, a password left in a code)
-   ...

# Images, audios and notes {background-color="#335c67"} 

Generative AI at its worst and best

## Image generation from text or image

* [Bing Chat](https://www.bing.com/images/create), [Dall-E](https://openai.com/index/dall-e-3/), [Midjourney](https://www.midjourney.com/home)
* Open weights models - [Flux](https://blackforestlabs.ai/), [Stable Diffusion](https://stability.ai/) (you'll need a decent GPU)
* [Perchance AI](https://perchance.org/ai-text-to-image-generator) (it's free, :point_right: try it !)
* [Prompt generator for image](https://huggingface.co/spaces/gokaygokay/FLUX-Prompt-Generator)
* Video models are starting to be really good ([Runway Gen-2](https://www.youtube.com/watch?v=71-yl2SYQpg), [ChatGPT Sora](https://www.youtube.com/watch?v=HK6y8DAPN_0))

::: {.notes}
short prompt: Ocean wind farms and solar panels in between. Focus on the solar panels. In the North sea. Image fit for scientific publication.
long prompt: Vast North Sea landscape with towering wind turbines and expansive solar panels stretching into the horizon, capturing the serene yet powerful energy of the ocean. Clear blue sky with wispy clouds, sunlight casting soft shadows. Solar panels glisten under the natural daylight, reflecting the azure waters. Cinematic wide shot with deep focus, inspired by the visual style of Christopher Nolan. Crisp, high-resolution image with minimal film grain, cool color grading emphasizing the technology and sustainability.
:::

::: {style="position:absolute;top:50%;left:0%;"}
::: {.r-stack}
![](images/ecompv.png){.fragment width="450" height="300"}

![](images/mussels.png){.fragment width="450" height="300"}

![](images/ammoniac.png){.fragment width="450" height="300"}

![](images/og_penguins.png){.fragment width="450" height="300"}

![](images/ecomod_logo.png){.fragment width="450" height="300"}

![](images/mfc_logo.png){.fragment width="450" height="300"}

![](images/mfc_logo2.png){.fragment width="450" height="300"}

![](images/sumo_logo1.png){.fragment width="450" height="300"}

![](images/sumo_logo2.png){.fragment width="450" height="300"}

![](images/sumo_logo3.png){.fragment width="450" height="300"}
:::
:::


## Audio generation from text

- [NotebookLM](https://notebooklm.google/) - podcast
{{< audio file="audio/converse_podcast.mp3" caption="From a paper (Ricour et al., 2023) on carbon sequestration fluxes (the full podcast is 10 min long)">}}
- [Suno](https://suno.com/), [udio](https://www.udio.com/) - music
{{< audio file="audio/coherens.mp3" caption="Based on COHERENS's documentation">}}

## Getting the info that matters the most

with [NotebookLM](https://notebooklm.google/), powered by Gemini 1.5

* Upload your sources (PDFs, websites, YouTube videos, Google Docs/Slides, ...)
* NotebookLM will summarize them and make connections (suggest questions) between topics
* Exact quotes from sources (relies only on uploaded documents)
* Multimodal - can analyse images and/or plots as well
* Confidential - data not used to train the model
* Helpful to summarize papers, anticipate questions, prepare presentations, ...

::: {.notes}
prepare presentations? At least you can check the outline of the presentation and see if it makes sense at that your key message is represented.
:::

# Coding can be fast {background-color="#335c67"}

Really fast.

## It feels like coding with 4 hands 

With [GitHub Copilot](https://github.com/features/copilot)

<!-- ![](gif/copilot_part1.gif) -->

<video controls width="900" height="540">
  <source src="./mp4/copilot_part1.mp4" type="video/mp4">
</video>

## Autocomplete, chat and command

<!-- ![](gif/copilot_part2.gif) -->

<video controls width="900" height="540">
  <source src="./mp4/copilot_part2.mp4" type="video/mp4">
</video>

::: {.fragment .fade-in}
[Codeium](https://codeium.com/) is also an alternative to GitHub Copilot
:::

## Shiny app built from scratch

Amazingly fast.

<video controls width="900" height="540">
  <source src="./mp4/shiny.mp4" type="video/mp4">
</video>

<!-- ![](gif/shiny.gif) -->

## New to Shiny? :point_right: [Try it](https://gallery.shinyapps.io/assistant/?email=florian.ricour%40naturalsciences.be&sig=4fc526dbed8fb8e702dce89edc1a13629c9132486ed923112b45ac3fca46ae99){preview-link="true"}!

A quick prompt - not strictly following the best practices !

```{.R code-copy=true}
Build an app with 

Dynamic dataset selection between built-in R datasets such as
<datasets>
quakes, iris, faithful, airquality, mtcars, CO2, USArrests and women
</datasets>
Automatic UI updates based on selected data

Multiple visualization options:
- Scatter plots with trend lines
- Box plots
- Violin plots

Interactive features:
- Variable selection for both axes
- Sample size control
- Data preview table
- Summary statistics
```

## [Artifacts](https://support.anthropic.com/en/articles/9487310-what-are-artifacts-and-how-do-i-use-them), a dedicated space for code

<video controls width="600" height="480">
  <source src="./mp4/mermaid.mp4" type="video/mp4">
</video>

::: {.fragment .fade-in}
::: {style="position:absolute;top:27%;left:55%;"}
* Documents (markdown or plain text)
* Code snippets (will not run except for some)
* Websites (HTML pages)
* SVG images
* Diagrams (e.g. mermaid flowcharts)
* Interactive React components
:::
:::

::: {.fragment .fade-in}
::: {style="position:absolute;top:85%;left:0%;"}
:eyes: I am not paid by Anthropic to promote Claude
:::
:::

## A rapidly evolving ecosystem :running:

Based on [Claude](https://www.anthropic.com/news/) (but the same applies for chatGPT & Co)

* Claude 3.5 Sonnet (Jun 21, 2024)
* Artifacts (Aug 27, 2024)
* Upgrade Claude 3.5 Sonnet (Oct 22, 2024)
* [Analysis tool](https://www.anthropic.com/news/analysis-tool) (Oct 24, 2024) - *Analyzing and visualizing data from CSV files*
* Claude 3.5 Sonnet on Github Copilot
* [Model Context Protocol](https://www.anthropic.com/news/model-context-protocol) (Nov 25, 2024) - *Connecting AI to data sources (Web, VScode, GitHub, ...)*

::: {.fragment .fade-in}
<span style="color: white;font-size: 24px;background-color:#335c67;border-radius: 10px">Next step</span>, AI agents
:::

## This is a personal conclusion :information_desk_person:

1.  Get on the train or be left at the station
2.  See it as an investment if the learning curve scares you
3.  Keep on learning - it's moving (way too) fast
4.  AI agents are coming (for you), be prepared
5.  Come back to this presentation in 2-3 years

# Feedback welcome ! {background-color="#335c67"}

# {background-image="https://media.giphy.com/media/3ohzdFCn9mYfmuAmEU/giphy.gif?cid=790b7611828zm4yal1njxp3a2v8uy0jrotuaxiu3j8p8hr3u&ep=v1_gifs_search&rid=giphy.gif&ct=g"}
